{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression learning algorithm using TensorFlow library.\n",
    "# Base example from Aymeric Damien, https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\n",
    "# Currently a loose idea of what we need to make a model for \n",
    "# Still need to read in data\n",
    "# MNIST data kept in comments just in case we need to retest something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# read in data from chosen files\n",
    "data = []\n",
    "labels = []\n",
    "# correct user is specified for which labels will be marked as '1'\n",
    "correctUser = \"hannah\"\n",
    "path = './data'\n",
    "\n",
    "# read in data from files\n",
    "for filename in os.listdir(path):\n",
    "    fp = open(\"./data/\"+filename, \"r\")\n",
    "    j = json.load(fp)\n",
    "\n",
    "    # after file is open put the json data into lists for training\n",
    "    for user in j:\n",
    "        if user == correctUser:\n",
    "            for attempt in j[user]:\n",
    "                templist = []\n",
    "                for key in attempt[\"Keys\"]:\n",
    "                    templist.append(key[\"Fight\"])\n",
    "                    templist.append(key[\"Dwell\"])\n",
    "                templist.append(attempt[\"Metadata\"][0][\"Total Time\"])\n",
    "                print \"-\"\n",
    "                data.append(templist)\n",
    "                labels.append(1)\n",
    "        else:\n",
    "            for attempt in j[user]:\n",
    "                templist = []\n",
    "                for key in attempt[\"Keys\"]:\n",
    "                    templist.append(key[\"Fight\"])\n",
    "                    templist.append(key[\"Dwell\"])\n",
    "                templist.append(attempt[\"Metadata\"][0][\"Total Time\"])\n",
    "                print \"-\"\n",
    "                data.append(templist)\n",
    "                labels.append(0)\n",
    "\n",
    "data = np.asarray(data)\n",
    "labels = tf.one_hot(labels,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize data input, feature scaling for better learning\n",
    "#theres probably a better way to do this but it works\n",
    "data = data.astype(float)\n",
    "for i in range(len(data)):\n",
    "    data[i] = (data[i] - np.mean(data[i])) / np.std(data[i])\n",
    "    \n",
    "#normThis = []\n",
    "#separate same values into separate lists to make math better\n",
    "#for j in range(len(data[0])):\n",
    "#    normThis.append([i[0] for i in data])\n",
    "    \n",
    "#print normThis[:2]\n",
    "#do the standardization\n",
    "#for i in range(len(normThis)):\n",
    "#    normThis[i] = (normThis[i] - np.mean(normThis[i])) / np.std(normThis[i])\n",
    "\n",
    "#print normThis[:2]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.2\n",
    "training_runs = 3000\n",
    "\n",
    "\n",
    "# tf Graph Input example from MNIST\n",
    "#x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "#y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# tf Graph Input for PIN\n",
    "x = tf.placeholder(tf.float32, [None, 9]) # each entry has \n",
    "y = tf.placeholder(tf.float32, [None, 2]) # one hot vector should be the output\n",
    "\n",
    "# Set model weights\n",
    "W1 = tf.Variable(tf.random_normal([9, 2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "#W1 = tf.Variable(tf.random_normal([9, 20]))\n",
    "#b1 = tf.Variable(tf.random_normal([20]))\n",
    "#W2 = tf.Variable(tf.zeros([20, 2]))\n",
    "#b2 = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W1) + b1)\n",
    "#z = tf.nn.softmax(tf.matmul(x, W1) + b1)\n",
    "#pred = tf.nn.softmax(tf.matmul(z, W2) + b2)\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "cost = -tf.reduce_sum(y*tf.log(tf.clip_by_value(pred,1e-10,1.0)))\n",
    "\n",
    "# Gradient Descent\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "[[ 0.07430176  0.92569822]\n",
      " [ 0.01495064  0.98504931]\n",
      " [ 0.01202176  0.98797822]\n",
      " [ 0.01026234  0.98973769]\n",
      " [ 0.0099756   0.99002433]\n",
      " [ 0.5719533   0.42804673]\n",
      " [ 0.00889244  0.99110764]\n",
      " [ 0.00853297  0.991467  ]\n",
      " [ 0.00857953  0.99142051]\n",
      " [ 0.00792118  0.99207884]\n",
      " [ 0.05573677  0.94426322]\n",
      " [ 0.01130966  0.98869032]\n",
      " [ 0.00944768  0.99055231]\n",
      " [ 0.00887838  0.99112165]\n",
      " [ 0.00845151  0.99154848]]\n",
      "40.1478\n",
      "16.0712\n",
      "10.7549\n",
      "8.95163\n",
      "8.59628\n",
      "8.45626\n",
      "8.32049\n",
      "8.17968\n",
      "8.07929\n",
      "7.99494\n",
      "7.91223\n",
      "7.83528\n",
      "7.76081\n",
      "7.68871\n",
      "7.61873\n",
      "7.55066\n",
      "7.48445\n",
      "7.42007\n",
      "7.3575\n",
      "7.29673\n",
      "7.23774\n",
      "7.18048\n",
      "7.12493\n",
      "7.07103\n",
      "7.01871\n",
      "6.96793\n",
      "6.91862\n",
      "6.8707\n",
      "6.82412\n",
      "6.7788\n",
      "6.73468\n",
      "6.69169\n",
      "6.64977\n",
      "6.60885\n",
      "6.56888\n",
      "6.52981\n",
      "6.49157\n",
      "6.45412\n",
      "6.41741\n",
      "6.3814\n",
      "6.34604\n",
      "6.3113\n",
      "6.27712\n",
      "6.24349\n",
      "6.21037\n",
      "6.17772\n",
      "6.14552\n",
      "6.11373\n",
      "6.08235\n",
      "6.05133\n",
      "6.02066\n",
      "5.99032\n",
      "5.96029\n",
      "5.93056\n",
      "5.9011\n",
      "5.8719\n",
      "5.84295\n",
      "5.81424\n",
      "5.78575\n",
      "5.75747\n",
      "5.7294\n",
      "5.70152\n",
      "5.67383\n",
      "5.64631\n",
      "5.61897\n",
      "5.5918\n",
      "5.56478\n",
      "5.53792\n",
      "5.51122\n",
      "5.48466\n",
      "5.45825\n",
      "5.43198\n",
      "5.40585\n",
      "5.37986\n",
      "5.354\n",
      "5.32827\n",
      "5.30268\n",
      "5.27722\n",
      "5.25189\n",
      "5.22668\n",
      "5.20161\n",
      "5.17666\n",
      "5.15185\n",
      "5.12716\n",
      "5.10259\n",
      "5.07815\n",
      "5.05384\n",
      "5.02966\n",
      "5.00561\n",
      "4.98168\n",
      "4.95788\n",
      "4.9342\n",
      "4.91066\n",
      "4.88724\n",
      "4.86395\n",
      "4.84078\n",
      "4.81775\n",
      "4.79484\n",
      "4.77206\n",
      "4.74941\n",
      "4.72688\n",
      "4.70449\n",
      "4.68222\n",
      "4.66008\n",
      "4.63807\n",
      "4.61618\n",
      "4.59443\n",
      "4.5728\n",
      "4.5513\n",
      "4.52992\n",
      "4.50867\n",
      "4.48755\n",
      "4.46656\n",
      "4.44569\n",
      "4.42494\n",
      "4.40432\n",
      "4.38383\n",
      "4.36346\n",
      "4.34321\n",
      "4.32309\n",
      "4.30309\n",
      "4.28321\n",
      "4.26346\n",
      "4.24382\n",
      "4.22431\n",
      "4.20491\n",
      "4.18564\n",
      "4.16648\n",
      "4.14744\n",
      "4.12852\n",
      "4.10971\n",
      "4.09102\n",
      "4.07245\n",
      "4.05398\n",
      "4.03564\n",
      "4.0174\n",
      "3.99928\n",
      "3.98127\n",
      "3.96336\n",
      "3.94557\n",
      "3.92789\n",
      "3.91031\n",
      "3.89285\n",
      "3.87548\n",
      "3.85823\n",
      "3.84107\n",
      "3.82403\n",
      "3.80708\n",
      "3.79024\n",
      "3.7735\n",
      "3.75686\n",
      "3.74032\n",
      "3.72387\n",
      "3.70753\n",
      "3.69128\n",
      "3.67513\n",
      "3.65907\n",
      "3.64311\n",
      "3.62725\n",
      "3.61147\n",
      "3.59579\n",
      "3.5802\n",
      "3.56469\n",
      "3.54929\n",
      "3.53396\n",
      "3.51873\n",
      "3.50358\n",
      "3.48852\n",
      "3.47355\n",
      "3.45866\n",
      "3.44385\n",
      "3.42913\n",
      "3.41449\n",
      "3.39993\n",
      "3.38545\n",
      "3.37106\n",
      "3.35674\n",
      "3.3425\n",
      "3.32835\n",
      "3.31426\n",
      "3.30026\n",
      "3.28633\n",
      "3.27247\n",
      "3.25869\n",
      "3.24498\n",
      "3.23135\n",
      "3.21778\n",
      "3.20429\n",
      "3.19088\n",
      "3.17753\n",
      "3.16425\n",
      "3.15104\n",
      "3.1379\n",
      "3.12483\n",
      "3.11182\n",
      "3.09888\n",
      "3.08601\n",
      "3.0732\n",
      "3.06046\n",
      "3.04778\n",
      "3.03517\n",
      "3.02262\n",
      "3.01013\n",
      "2.9977\n",
      "2.98534\n",
      "2.97303\n",
      "2.96078\n",
      "2.9486\n",
      "2.93648\n",
      "2.92441\n",
      "2.9124\n",
      "2.90045\n",
      "2.88856\n",
      "2.87672\n",
      "2.86494\n",
      "2.85321\n",
      "2.84154\n",
      "2.82993\n",
      "2.81837\n",
      "2.80687\n",
      "2.79541\n",
      "2.78401\n",
      "2.77267\n",
      "2.76137\n",
      "2.75013\n",
      "2.73894\n",
      "2.72779\n",
      "2.7167\n",
      "2.70566\n",
      "2.69467\n",
      "2.68373\n",
      "2.67284\n",
      "2.66199\n",
      "2.65119\n",
      "2.64045\n",
      "2.62975\n",
      "2.61909\n",
      "2.60849\n",
      "2.59793\n",
      "2.58741\n",
      "2.57694\n",
      "2.56652\n",
      "2.55614\n",
      "2.54581\n",
      "2.53551\n",
      "2.52527\n",
      "2.51507\n",
      "2.50491\n",
      "2.49479\n",
      "2.48472\n",
      "2.47469\n",
      "2.46471\n",
      "2.45476\n",
      "2.44485\n",
      "2.43499\n",
      "2.42517\n",
      "2.41539\n",
      "2.40564\n",
      "2.39595\n",
      "2.38629\n",
      "2.37667\n",
      "2.36708\n",
      "2.35754\n",
      "2.34804\n",
      "2.33858\n",
      "2.32915\n",
      "2.31976\n",
      "2.31042\n",
      "2.30111\n",
      "2.29184\n",
      "2.2826\n",
      "2.2734\n",
      "2.26424\n",
      "2.25511\n",
      "2.24603\n",
      "2.23697\n",
      "2.22796\n",
      "2.21898\n",
      "2.21003\n",
      "2.20113\n",
      "2.19225\n",
      "2.18341\n",
      "2.17461\n",
      "2.16584\n",
      "2.15711\n",
      "2.14841\n",
      "2.13974\n",
      "2.13111\n",
      "2.12252\n",
      "2.11395\n",
      "2.10543\n",
      "2.09693\n",
      "2.08846\n",
      "2.08003\n",
      "2.07164\n",
      "2.06327\n",
      "2.05494\n",
      "2.04664\n",
      "2.03837\n",
      "2.03013\n",
      "All done!\n",
      "predictions: [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
      "[[  9.72870171e-01   2.71298550e-02]\n",
      " [  9.97611284e-01   2.38868594e-03]\n",
      " [  9.98815894e-01   1.18408247e-03]\n",
      " [  9.69773889e-01   3.02261803e-02]\n",
      " [  9.86355126e-01   1.36448285e-02]\n",
      " [  1.00000000e+00   0.00000000e+00]\n",
      " [  8.48946869e-01   1.51053086e-01]\n",
      " [  8.22156250e-01   1.77843735e-01]\n",
      " [  7.76670396e-01   2.23329633e-01]\n",
      " [  7.51752317e-01   2.48247668e-01]\n",
      " [  4.23017199e-13   1.00000000e+00]\n",
      " [  4.73083593e-02   9.52691615e-01]\n",
      " [  1.17921829e-01   8.82078230e-01]\n",
      " [  3.67078304e-01   6.32921636e-01]\n",
      " [  3.41242015e-01   6.58757985e-01]]\n",
      "actual:  [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "l = sess.run(labels)\n",
    "#print data\n",
    "#print l\n",
    "\n",
    "# Training cycle\n",
    "print \"predictions:\", tf.argmax(pred.eval(feed_dict={x:data[:15]}),1).eval()\n",
    "print pred.eval(feed_dict={x:data[:15]})\n",
    "for i in range(training_runs):\n",
    "    # Fit training using json data\n",
    "    _, error = sess.run([optimizer, cost], {x:data[:15], y:l[:15]})\n",
    "\n",
    "    # Print error every once and a while to see whats going on\n",
    "    if (i % 10) == 0:\n",
    "        #print sess.run(W1)\n",
    "        #print sess.run(b1)\n",
    "        print error\n",
    "\n",
    "print \"All done!\"\n",
    "print \"predictions:\", tf.argmax(pred.eval(feed_dict={x:data[:15]}),1).eval()\n",
    "print pred.eval(feed_dict={x:data[:15]})\n",
    "print \"actual: \", l[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "y: [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (5, 784) for Tensor u'Placeholder_16:0', which has shape '(?, 9)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f25090cac8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Fit training using batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n\u001b[0;32m---> 17\u001b[0;31m                                                           y: batch_ys})\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# Compute average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (5, 784) for Tensor u'Placeholder_16:0', which has shape '(?, 9)'"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "# not using, this is just a reference\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(10):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/200)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(200)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "            print sess.run(b1)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
